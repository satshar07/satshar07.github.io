<div class="custom-layout">
  <div class="col-left" markdown="1">
# Satyam Sharma
**Computer Science + Operations Research + Math @ Cal ('25)**

I work on ML/AI systems under real constraints like limited compute, imperfect data, and in stringent production environments. My focus has been on taking state-of-the-art ideas out of papers and into real systems, and understanding why they often fail in practice. 

Areas I've been reading into/exploring recently revolve around performance engineering, inference-time optimizations, agents, and robotics. 

**Contact:** [satshar0@gmail.com](mailto:satshar0@gmail.com)
  </div>

  <div class="col-mid" markdown="1">
## Research

### Dynamic Hyperparameter Optimization
<p class="tldr">TLDR: Showed why online hyperparameter methods often underperform static baselines.</p>
Evaluating Population-Based Training and hypergradient-style updates for Vision Transformers. Found many adaptive methods converge to conservative regimes due to short-horizon optimization. Pending publication.

***

### EnsembleGold â€” Monocular Depth
<p class="tldr">TLDR: Improved diffusion-based depth estimation using inference-time techniques only.</p>
Achieved a significant (~10-20%) improvement on various error metrics on zero-shot monocular depth estimation without retraining. Thank you to Prof. Jitendra Malik and Prof. Anjoo Kanazawa.
  </div>

  <div class="col-right" markdown="1">
## Commercial / Mission-Facing

### Second Front Systems
<p class="tldr">TLDR: Agentic system for vulnerability remediation in defense software.</p>
Built an engine reasoning over SBOMs and dependency graphs to propose fixes. Work highlighted at a Second Front investor meeting.

***

### Falkonry
<p class="tldr">TLDR: Modeled adversarial EW signals under intentional distribution shift.</p>
Focused on latent state inference under non-stationary dynamics. Separated structured behavior from deception.

## Technical Skills
Python; PyTorch; NumPy; mixed-precision training (FP16, BF16); distributed training and inference; Vision Transformers; diffusion models; ensemble and test-time inference methods; latent-variable and state-space modeling; learning under non-IID, adversarial, and non-stationary data; graph-based dependency analysis (SBOMs); agent-based automated reasoning systems
  </div>
</div>
